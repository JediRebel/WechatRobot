// scripts/fetch-all.ts
/* eslint-disable no-console */

import minimist from "minimist"
import Parser from "rss-parser"
import { SCRAPER_CONFIGS } from "../src/scraper-configs"
import {
  AnyScraperConfig,
  HtmlScraperConfig,
  RssScraperConfig,
  isHtmlConfig,
  isRssConfig,
  ScrapeOptions,
} from "../src/utils/types"
import { scrapeByConfig as scrapeHtml } from "../src/scrapers/genericScraper"
import { scrape as scrapeRcmp } from "../src/scrapers/rcmp"
import { scrape as scrapeSaintAndrews } from "../src/scrapers/saint-andrews"
import fs from "fs"
import path from "path"
import { browserManager } from "../src/utils/browser-manager"
// ğŸš¨ å¼•å…¥æ•°æ®åº“å·¥å…·
import { saveNewsItems } from "../src/utils/db"

// ========== CLI å‚æ•° ==========
const argv = minimist(process.argv.slice(2), {
  boolean: ["debug", "ignoreWindow", "all"],
  string: ["only", "windowHours", "show", "json"],
  alias: {
    d: "debug",
    i: "ignoreWindow",
    a: "all",
    o: "only",
  },
  default: {
    debug: false,
    ignoreWindow: false,
    all: false,
    show: "3",
  },
})

const showLimit = Number(argv.show) || 3
const jsonPath = (argv.json || "").toString().trim()
const baseOpts: ScrapeOptions = {
  debug: !!argv.debug,
  ignoreWindow: !!argv.ignoreWindow,
  // windowHours: argv.windowHours ? Number(argv.windowHours) : undefined,
  windowHours: argv.windowHours ? Number(argv.windowHours) : 24,
}

const onlyId = (argv.only || "").toString().trim()
const testAll = !!argv.all || !onlyId

let configsToTest: AnyScraperConfig[]
if (onlyId) {
  configsToTest = SCRAPER_CONFIGS.filter((c) => c.id === onlyId)
} else if (testAll) {
  configsToTest = SCRAPER_CONFIGS
} else {
  configsToTest = SCRAPER_CONFIGS
}

console.log(
  "å‚æ•°ï¼šdebug=%s, ignoreWindow=%s, windowHours=%s, show=%s, only=%s, all=%s\n",
  baseOpts.debug,
  baseOpts.ignoreWindow,
  baseOpts.windowHours ?? "(default)",
  showLimit,
  onlyId || "(none)",
  testAll,
)

if (!configsToTest.length) {
  console.error("âŒ æ²¡æœ‰æ‰¾åˆ°è¦æµ‹è¯•çš„é…ç½®ï¼ˆæ£€æŸ¥ id æ˜¯å¦æ­£ç¡®ï¼‰")
  process.exit(1)
}

const rssParser = new Parser()
const aggregated: Array<{
  sourceId: string
  name: string
  items: {
    title: string
    link: string
    dateISO?: string
    source: string
    date?: Date
  }[]
}> = []

async function run() {
  try {
    for (const config of configsToTest) {
      if (!config.enabled) {
        console.log(`â­ï¸  [${config.id}] ${config.name} (disabled)`)
        continue
      }

      try {
        if (isHtmlConfig(config)) {
          if (config.id === "rcmp-nb") {
            await testRcmp(baseOpts)
          } else if (config.id === "town-saint-andrews") {
            await testSaintAndrews(baseOpts)
          } else {
            await testHtml(config, baseOpts)
          }
        } else if (isRssConfig(config)) {
          await testRss(config, baseOpts)
        } else {
          console.log(
            `â“ [${(config as any).id}] Unknown kind: ${(config as any).kind}`,
          )
        }
      } catch (err) {
        console.error(
          `âŒ [${(config as any).id}] error:`,
          (err as Error).message,
        )
      }

      console.log()
    }

    // ğŸš¨ å…³é”®æ”¹è¿›ï¼šåœ¨æ‰€æœ‰æŠ“å–å®Œæˆåï¼Œå°†ç»“æœå­˜å…¥æ•°æ®åº“è¿›è¡ŒæŒä¹…åŒ–å»é‡
    console.log("ğŸ’¾ æ­£åœ¨å°†æ–°æ–°é—»å­˜å…¥æ•°æ®åº“...")
    const allItems = aggregated.flatMap((group) => group.items)
    if (allItems.length > 0) {
      try {
        await saveNewsItems(allItems)
        console.log(
          `âœ… å·²å¤„ç† ${allItems.length} æ¡æ–°é—»å…¥åº“ï¼ˆé‡å¤é¡¹å·²è‡ªåŠ¨å¿½ç•¥ï¼‰ã€‚`,
        )
      } catch (dbErr) {
        // å³ä½¿å…¥åº“å¤±è´¥ï¼Œæˆ‘ä»¬ä¹Ÿå¸Œæœ›çœ‹åˆ°é‡‡é›†å®Œæˆçš„æç¤ºï¼Œä¸è¦è®©æ•°æ®åº“é”™è¯¯é˜»å¡æ•´ä¸ªæµç¨‹
        console.error("âŒ æ•°æ®åº“å…¥åº“å¤±è´¥ï¼Œä½†é‡‡é›†å·²å®Œæˆ:", dbErr)
      }
    }

    console.log("ğŸ å…¨éƒ¨æµ‹è¯•å®Œæˆã€‚")
  } finally {
    if (
      configsToTest.some(
        (c) => c.id === "rcmp-nb" || c.id === "town-saint-andrews",
      )
    ) {
      console.log("æ‰«é™¤ï¼šæ­£åœ¨å…³é—­å¸¸é©»æµè§ˆå™¨...")
      await browserManager.closeBrowser()
    }
  }

  if (jsonPath) {
    const out = aggregated
    const outFile =
      jsonPath.startsWith(".") || jsonPath.startsWith("/")
        ? jsonPath
        : path.join(process.cwd(), jsonPath)
    fs.mkdirSync(path.dirname(outFile), { recursive: true })
    fs.writeFileSync(outFile, JSON.stringify(out, null, 2), "utf8")
    console.log(`ğŸ“ Aggregated JSON saved to ${outFile}`)
  }
  process.exit(0)
}

// ========== HTML ==========
async function testHtml(config: HtmlScraperConfig, opts: ScrapeOptions) {
  console.log(`ğŸ” æ­£åœ¨çˆ¬å–: [${config.id}] ${config.name}`)
  const items = await scrapeHtml(config, opts)
  const show = Math.min(showLimit, items.length)
  console.log(
    `âœ… [${config.id}] got ${items.length} items. Showing first ${show}:`,
  )
  console.dir(items.slice(0, show), { depth: null })
  aggregated.push({
    sourceId: config.id,
    name: config.name,
    items: items.map((it) => ({
      title: it.title,
      link: it.link,
      dateISO: it.date ? it.date.toISOString() : undefined,
      date: it.date,
      source: it.source,
    })),
  })
}

// ========== RSS ==========
async function testRss(config: RssScraperConfig, _opts: ScrapeOptions) {
  console.log(`ğŸ” æ­£åœ¨çˆ¬å– RSS: [${config.id}] ${config.name}`)
  const parser = config.headers
    ? new Parser({ headers: config.headers })
    : rssParser

  try {
    const feed = await parser.parseURL(config.url)
    let items = feed.items || []

    if (!_opts.ignoreWindow && _opts.windowHours) {
      const now = Date.now()
      const windowMs = _opts.windowHours * 3600 * 1000
      items = items.filter((it) => {
        const d = it.isoDate || it.pubDate
        if (!d) return false
        const t = Date.parse(d)
        if (Number.isNaN(t)) return false
        return now - t <= windowMs
      })
    }

    if (config.maxItems && items.length > config.maxItems) {
      items = items.slice(0, config.maxItems)
    }

    const show = Math.min(showLimit, items.length)
    console.log(
      `âœ… [${config.id}] got ${items.length} items. Showing first ${show}:`,
    )

    aggregated.push({
      sourceId: config.id,
      name: config.name,
      items: (items || []).map((it) => ({
        title: it.title || "",
        link: it.link || "",
        dateISO: it.isoDate || it.pubDate,
        date: it.isoDate
          ? new Date(it.isoDate)
          : it.pubDate
          ? new Date(it.pubDate)
          : undefined,
        source: config.id,
      })),
    })
  } catch (e) {
    console.error(`âŒ [${(config as any).id}] error:`, (e as Error).message)
  }
}

// ========== RCMP ç‰¹æ®Š (Puppeteer Managed) ==========
async function testRcmp(opts: ScrapeOptions) {
  console.log("ğŸ” Testing RCMP NB (managed dynamic scraper)")
  const items = await scrapeRcmp(opts)
  const show = Math.min(showLimit, items.length)
  console.log(`âœ… [rcmp-nb] got ${items.length} items. Showing first ${show}:`)
  aggregated.push({
    sourceId: "rcmp-nb",
    name: "RCMP New Brunswick",
    items: items.map((it) => ({
      title: it.title,
      link: it.link,
      dateISO: it.date ? it.date.toISOString() : undefined,
      date: it.date,
      source: it.source,
    })),
  })
}

// ========== Saint Andrews ç‰¹æ®Š (Puppeteer Managed) ==========
async function testSaintAndrews(opts: ScrapeOptions) {
  console.log(
    "ğŸ” Testing Town of Saint Andrews (managed dynamic scraper for 403 bypass)",
  )
  const items = await scrapeSaintAndrews(opts)
  const show = Math.min(showLimit, items.length)
  console.log(
    `âœ… [town-saint-andrews] got ${items.length} items. Showing first ${show}:`,
  )
  aggregated.push({
    sourceId: "town-saint-andrews",
    name: "Town of Saint Andrews",
    items: items.map((it) => ({
      title: it.title,
      link: it.link,
      dateISO: it.date ? it.date.toISOString() : undefined,
      date: it.date,
      source: it.source,
    })),
  })
}

void run()
