/* eslint-disable no-console */

import minimist from "minimist"
import Parser from "rss-parser"
import { SCRAPER_CONFIGS } from "../src/scraper-configs"
import {
  AnyScraperConfig,
  HtmlScraperConfig,
  RssScraperConfig,
  isHtmlConfig,
  isRssConfig,
  ScrapeOptions,
} from "../src/utils/types"
import { scrapeByConfig as scrapeHtml } from "../src/scrapers/genericScraper"
import { scrape as scrapeRcmp } from "../src/scrapers/rcmp"
import { scrape as scrapeSaintAndrews } from "../src/scrapers/saint-andrews"
import fs from "fs"
import path from "path"
import { browserManager } from "../src/utils/browser-manager"
import { saveNewsItems } from "../src/utils/db"
import OpenAI from "openai"

// ========== CLI å‚æ•° ==========
const argv = minimist(process.argv.slice(2), {
  boolean: ["debug", "ignoreWindow", "all", "prod"],
  string: ["only", "windowHours", "show", "json"],
  alias: {
    d: "debug",
    i: "ignoreWindow",
    a: "all",
    o: "only",
    p: "prod",
  },
  default: {
    debug: false,
    ignoreWindow: false,
    all: false,
    show: "3",
    prod: false,
  },
})

const showLimit = Number(argv.show) || 3
const jsonPath = (argv.json || "").toString().trim()
const baseOpts: ScrapeOptions = {
  debug: !!argv.debug,
  ignoreWindow: !!argv.ignoreWindow,
  windowHours: argv.windowHours ? Number(argv.windowHours) : 24,
}

const onlyId = (argv.only || "").toString().trim()
const testAll = !!argv.all || !onlyId

let configsToTest: AnyScraperConfig[]
if (onlyId) {
  configsToTest = SCRAPER_CONFIGS.filter((c) => c.id === onlyId)
} else if (testAll) {
  configsToTest = SCRAPER_CONFIGS
} else {
  configsToTest = SCRAPER_CONFIGS
}

console.log(
  "å‚æ•°ï¼šdebug=%s, ignoreWindow=%s, windowHours=%s, show=%s, only=%s, all=%s, prod=%s\n",
  baseOpts.debug,
  baseOpts.ignoreWindow,
  baseOpts.windowHours ?? "(default)",
  showLimit,
  onlyId || "(none)",
  testAll,
  argv.prod,
)

const rssParser = new Parser()
const aggregated: Array<{
  sourceId: string
  name: string
  items: {
    title: string
    link: string
    dateISO?: string
    source: string
    date?: Date
  }[]
}> = []

// ========== ğŸš¨ è¯­ä¹‰å»é‡æ ¸å¿ƒå‡½æ•° ==========
const dateBucket = (d?: Date) => {
  if (d instanceof Date && !Number.isNaN(d.getTime())) {
    return d.toISOString().slice(0, 10) // æŒ‰æ—¥åˆ†æ¡¶ï¼Œé˜²æ­¢é•¿å‘¨æœŸè¯¯å¹¶
  }
  return new Date().toISOString().slice(0, 10)
}

async function clusterNewsByAI(items: any[]) {
  if (items.length <= 1) return items

  const shortTitleRatio =
    items.filter((it) => (it.title || "").trim().length <= 8).length /
    items.length
  // å…¨æ˜¯æçŸ­æ ‡é¢˜æ—¶ï¼Œè·³è¿‡ AIï¼Œé˜²è¯¯å¹¶
  if (shortTitleRatio > 0.7) {
    return items.map((it) => ({
      ...it,
      cluster_key: `${it.title}||${dateBucket(it.date)}`,
    }))
  }

  console.log(`ğŸ¤– æ­£åœ¨è¯·æ±‚ AI è¿›è¡Œè¯­ä¹‰å»é‡ï¼ˆå¤„ç† ${items.length} æ¡æ•°æ®ï¼‰...`)
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  const prompt = `
    ä½ æ˜¯ä¸€ä¸ªæ–°é—»å»é‡åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹æ–°é—»æ ‡é¢˜åˆ—è¡¨ï¼Œå°†æè¿°åŒä¸€äº‹ä»¶çš„æ ‡é¢˜å½’ä¸ºä¸€ç»„ã€‚
    è¦æ±‚ï¼šä¸ºæ¯ç»„æ–°é—»ç”Ÿæˆä¸€ä¸ªç®€çŸ­ã€æ ‡å‡†çš„ä¸­æ–‡æ ¸å¿ƒæ ‡é¢˜ä½œä¸º "cluster_key"ã€‚
    è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
    [{"idx": 0, "cluster_key": "æ ‡å‡†åŒ–æ ‡é¢˜1"}, {"idx": 1, "cluster_key": "æ ‡å‡†åŒ–æ ‡é¢˜1"}]
    
    æ–°é—»åˆ—è¡¨ï¼š
    ${items.map((it, idx) => `${idx}: ${it.title}`).join("\n")}
  `
  try {
    const completion = await openai.chat.completions.create({
      messages: [{ role: "user", content: prompt }],
      model: "gpt-4o-mini",
      response_format: { type: "json_object" },
    })
    const content = completion.choices[0].message.content
    if (!content) return items
    const result = JSON.parse(content)
    const mappings = Array.isArray(result) ? result : result.clusters || []
    return items.map((it, idx) => {
      const match = mappings.find((m: any) => m.idx === idx)
      const baseKey = match && match.cluster_key ? match.cluster_key : it.title
      return { ...it, cluster_key: `${baseKey}||${dateBucket(it.date)}` }
    })
  } catch (err) {
    console.error("âŒ AI èšç±»å¤±è´¥ï¼Œå›é€€åˆ°æ ‡é¢˜å»é‡:", err)
    return items.map((it) => ({
      ...it,
      cluster_key: `${it.title}||${dateBucket(it.date)}`,
    }))
  }
}

async function run() {
  try {
    for (const config of configsToTest) {
      if (!config.enabled) {
        console.log(`â­ï¸  [${config.id}] ${config.name} (disabled)`)
        continue
      }
      try {
        if (isHtmlConfig(config)) {
          if (config.id === "rcmp-nb") {
            await testRcmp(baseOpts)
          } else if (config.id === "town-saint-andrews") {
            await testSaintAndrews(baseOpts)
          } else {
            await testHtml(config, baseOpts)
          }
        } else if (isRssConfig(config)) {
          await testRss(config, baseOpts)
        } else {
          console.log(
            `â“ [${(config as any).id}] Unknown kind: ${(config as any).kind}`,
          )
        }
      } catch (err) {
        console.error(
          `âŒ [${(config as any).id}] error:`,
          (err as Error).message,
        )
      }
      console.log()
    }

    let allItems = aggregated.flatMap((group) =>
      group.items.map((it) => ({
        title: it.title,
        link: it.link,
        source: it.source || group.sourceId,
        date: it.date,
        content: (it as any).content,
      })),
    )

    console.log(
      `\nğŸ“Š æŠ“å–æ±‡æ€»ï¼šå…±ä» ${aggregated.length} ä¸ªæºä¸­æŠ“å–åˆ° ${allItems.length} æ¡æ–°é—»ã€‚`,
    )

    if (argv.prod) {
      console.log("ğŸš€ [Production æ¨¡å¼] å‡†å¤‡æ‰§è¡Œ AI èšç±»å¹¶åŒæ­¥è‡³æ•°æ®åº“...")
      if (allItems.length > 0) {
        allItems = await clusterNewsByAI(allItems)
        try {
          await saveNewsItems(allItems)
          console.log(`âœ… æ•°æ®åº“å…¥åº“å®Œæˆã€‚`)
        } catch (dbErr) {
          console.error("âŒ æ•°æ®åº“å†™å…¥å¤±è´¥:", dbErr)
        }
      }
    } else {
      console.log("ğŸ§ª [Test æ¨¡å¼] å·²è·³è¿‡æ•°æ®åº“å…¥åº“ã€‚")
      const testOutDir = path.join(process.cwd(), "out")
      if (!fs.existsSync(testOutDir)) fs.mkdirSync(testOutDir)
      const testFile = path.join(testOutDir, "latest-fetch-test.json")
      fs.writeFileSync(testFile, JSON.stringify(allItems, null, 2), "utf8")
      console.log(`ğŸ“ æŠ“å–ç»“æœé¢„è§ˆå·²ä¿å­˜è‡³: ${testFile}`)
    }
    console.log("ğŸ å…¨éƒ¨æŠ“å–ä»»åŠ¡ç»“æŸã€‚")
  } catch (globalErr) {
    console.error("âŒ å…¨å±€è¿è¡Œå¼‚å¸¸:", globalErr)
  } finally {
    if (
      configsToTest.some(
        (c) => c.id === "rcmp-nb" || c.id === "town-saint-andrews",
      )
    ) {
      console.log("ğŸ§¹ æ­£åœ¨å…³é—­å¸¸é©»æµè§ˆå™¨...")
      await browserManager.closeBrowser()
    }
  }
}

// ========== æ¢å¤å±•ç¤ºè¯¦æƒ…çš„è¾…åŠ©å‡½æ•° ==========

async function testHtml(config: HtmlScraperConfig, opts: ScrapeOptions) {
  console.log(`ğŸ” æ­£åœ¨çˆ¬å–: [${config.id}] ${config.name}`)
  const items = await scrapeHtml(config, opts)
  const show = Math.min(showLimit, items.length)
  console.log(
    `âœ… [${config.id}] got ${items.length} items. Showing first ${show}:`,
  )
  // ğŸš¨ æ¢å¤è¯¦æƒ…æ‰“å°
  console.dir(items.slice(0, show), { depth: null })
  aggregated.push({
    sourceId: config.id,
    name: config.name,
    items: items.map((it) => ({
      title: it.title,
      link: it.link,
      dateISO: it.date ? it.date.toISOString() : undefined,
      date: it.date,
      source: it.source,
      content: (it as any).content,
    })),
  })
}

async function testRss(config: RssScraperConfig, _opts: ScrapeOptions) {
  console.log(`ğŸ” æ­£åœ¨çˆ¬å– RSS: [${config.id}] ${config.name}`)
  const parser = config.headers
    ? new Parser({ headers: config.headers })
    : rssParser
  try {
    const feed = await parser.parseURL(config.url)
    let items = feed.items || []
    if (!_opts.ignoreWindow && _opts.windowHours) {
      const now = Date.now()
      const windowMs = _opts.windowHours * 3600 * 1000
      items = items.filter((it) => {
        const d = it.isoDate || it.pubDate
        if (!d) return false
        const t = Date.parse(d)
        return !Number.isNaN(t) && now - t <= windowMs
      })
    }
    const show = Math.min(showLimit, items.length)
    console.log(
      `âœ… [${config.id}] got ${items.length} items. Showing first ${show}:`,
    )

    const mappedItems = (items || []).map((it) => ({
      title: it.title || "",
      link: it.link || "",
      dateISO: it.isoDate || it.pubDate,
      date: it.isoDate
        ? new Date(it.isoDate)
        : it.pubDate
        ? new Date(it.pubDate)
        : undefined,
      source: config.id,
      content: (it as any).content,
    }))
    // ğŸš¨ æ¢å¤è¯¦æƒ…æ‰“å°
    console.dir(mappedItems.slice(0, show), { depth: null })

    aggregated.push({
      sourceId: config.id,
      name: config.name,
      items: mappedItems,
    })
  } catch (e) {
    console.error(`âŒ [${config.id}] error:`, (e as Error).message)
  }
}

async function testRcmp(opts: ScrapeOptions) {
  console.log("ğŸ” Testing RCMP NB (managed dynamic scraper)")
  const items = await scrapeRcmp(opts)
  const show = Math.min(showLimit, items.length)
  console.log(`âœ… [rcmp-nb] got ${items.length} items. Showing first ${show}:`)
  // ğŸš¨ æ¢å¤è¯¦æƒ…æ‰“å°
  console.dir(items.slice(0, show), { depth: null })
  aggregated.push({
    sourceId: "rcmp-nb",
    name: "RCMP NB",
    items: items.map((it) => ({ ...it, source: it.source, content: (it as any).content })),
  })
}

async function testSaintAndrews(opts: ScrapeOptions) {
  console.log("ğŸ” Testing Town of Saint Andrews")
  const items = await scrapeSaintAndrews(opts)
  const show = Math.min(showLimit, items.length)
  console.log(
    `âœ… [town-saint-andrews] got ${items.length} items. Showing first ${show}:`,
  )
  // ğŸš¨ æ¢å¤è¯¦æƒ…æ‰“å°
  console.dir(items.slice(0, show), { depth: null })
  aggregated.push({
    sourceId: "town-saint-andrews",
    name: "Saint Andrews",
    items: items.map((it) => ({ ...it, source: it.source, content: (it as any).content })),
  })
}

void run()
