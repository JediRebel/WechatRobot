// src/scrapers/rcmp.ts
/* eslint-disable no-console */

import * as cheerio from "cheerio"
import axios from "axios" // ç”¨ axios æŠ“è¯¦æƒ…é¡µæ›´å¿«
import { NewsArticle, ScrapeOptions } from "../utils/types"
import { isWithinTimeWindow } from "../utils/helpers"
// ğŸš¨ å¼•å…¥å•ä¾‹ç®¡ç†å™¨
import { browserManager } from "../utils/browser-manager"

// å·¥å…·ï¼šå¤„ç†ç›¸å¯¹è·¯å¾„
function absUrl(href: string): string {
  if (!href) return ""
  if (/^https?:\/\//i.test(href)) return href
  return new URL(href, "https://rcmp.ca").toString()
}

// å·¥å…·ï¼šä» HTML å­—ç¬¦ä¸²ä¸­æå– href
function extractLink(html: string): string {
  const m = html.match(/href\s*=\s*(?:"([^"]+)"|'([^']+)'|([^\s>]+))/i)
  const raw = m?.[1] || m?.[2] || m?.[3] || ""
  return raw ? absUrl(raw) : ""
}

// å·¥å…·ï¼šå»é™¤ HTML æ ‡ç­¾
function stripHtml(html: string): string {
  return html
    .replace(/<[^>]+>/g, "")
    .replace(/\s+/g, " ")
    .trim()
}

/**
 * æŠ“å– RCMP æ–°é—»çš„æ··åˆç­–ç•¥ï¼š
 * 1. BrowserManager: è·å– Page æ¸²æŸ“åˆ—è¡¨é¡µï¼Œè·å– DataTables é‡Œçš„é“¾æ¥ã€‚
 * 2. Axios + Cheerio: æ‹¿åˆ°é“¾æ¥åï¼Œå¹¶å‘æŠ“å–è¯¦æƒ…é¡µæ­£æ–‡ã€‚
 */
export async function scrape(opts: ScrapeOptions = {}): Promise<NewsArticle[]> {
  // ğŸš¨ ä½¿ç”¨ç®¡ç†å™¨è·å–æ–°é¡µé¢ï¼Œä¸å†æ‰‹åŠ¨ launch
  const page = await browserManager.newPage()

  try {
    if (opts.debug) console.log("[rcmp-nb] Using managed browser for list...")

    // 1. æ‰“å¼€åˆ—è¡¨é¡µ
    await page.goto("https://rcmp.ca/en/nb/news", {
      waitUntil: "networkidle2",
      timeout: 60000,
    })

    // 2. ç­‰å¾… DataTables åŠ è½½æ•°æ®
    await page.waitForFunction(
      () =>
        (window as any).jQuery &&
        (window as any)
          .jQuery("#n")
          .DataTable()
          .data().length > 0,
      { timeout: 20000 },
    )

    // 3. ä»å†…å­˜ä¸­ç›´æ¥è¯»å– DataTables çš„æ•°æ®
    const rows = await page.evaluate(() => {
      const $ = (window as any).jQuery
      const dt = $("#n").DataTable()
      return dt.data().toArray()
    })

    if (opts.debug)
      console.log(`[rcmp-nb] Found ${rows.length} rows in DataTable.`)

    // 4. åˆæ­¥ç­›é€‰ (æ—¶é—´ + æ ¼å¼)
    const candidates: NewsArticle[] = []
    for (const r of rows) {
      const titleHtml: string = r.title || ""
      const link = extractLink(titleHtml)
      const title = stripHtml(titleHtml)
      const dateStr: string = r.date || ""
      const date = dateStr ? new Date(dateStr) : new Date()

      if (!title || !link) continue

      // æ—¶é—´è¿‡æ»¤
      if (!opts.ignoreWindow && !isWithinTimeWindow(date.toISOString()))
        continue

      candidates.push({
        title,
        link,
        date,
        source: "rcmp-nb",
        content: "",
      })
    }

    // ğŸš¨ å…³é—­å½“å‰é¡µé¢ï¼Œè€Œä¸æ˜¯å…³é—­æ•´ä¸ªæµè§ˆå™¨
    await page.close()

    // æˆªå–å‰ 10 æ¡ï¼Œé¿å…ä¸€æ¬¡æŠ“å¤ªå¤š
    const targets = candidates.slice(0, 10)
    if (opts.debug)
      console.log(`[rcmp-nb] Fetching details for ${targets.length} items...`)

    // 5. å¹¶å‘æŠ“å–è¯¦æƒ…é¡µæ­£æ–‡
    await Promise.all(
      targets.map(async (item) => {
        try {
          const { data: html } = await axios.get(item.link, {
            headers: { "User-Agent": "Mozilla/5.0 (compatible; Scraper/1.0)" },
            timeout: 10000,
          })
          const $ = cheerio.load(html)

          $("script, style, nav, header, footer, .alert").remove()

          let content =
            $("main article")
              .text()
              .trim() ||
            $("main #wb-cont")
              .nextAll()
              .text()
              .trim() ||
            $("main")
              .text()
              .trim()

          content = content.replace(/\s+/g, " ").slice(0, 5000)
          item.content = content
        } catch (e) {
          if (opts.debug)
            console.error(`[rcmp-nb] Failed to fetch detail: ${item.link}`)
        }
      }),
    )

    return targets
  } catch (e) {
    console.error("[rcmp-nb] scrape failed:", (e as Error).message)
    // ğŸš¨ å³ä½¿å¤±è´¥ä¹Ÿè¦ç¡®ä¿é¡µé¢å…³é—­ï¼Œé˜²æ­¢å¥æŸ„æ³„éœ²
    if (!page.isClosed()) await page.close()
    return []
  }
}
